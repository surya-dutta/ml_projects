# -*- coding: utf-8 -*-
"""ECE759_software_project_code_sdutta5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ID0Q6xTPMc603qxCj491I4AFWk5DuViT

ECE 759 PATTERN RECOGNITION\
Software Project Fall 2023\
Submitted by - Surya Dutta (SID: 200481187)
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from scipy.spatial.distance import cityblock
from collections import Counter

# Load Iris dataset
iris = load_iris()
X, y = iris.data, iris.target
class_names = iris.target_names

# Splitting the dataset into training and testing sets
X_train, y_train = X, y

# Function to implement the kthperclass classifier
def kthperclass_classifier(X_train, y_train, X_test, k):
    predictions = []
    classes = np.unique(y_train)

    for test_point in X_test:
        fom_per_class = []

        for cls in classes:
            class_points = X_train[y_train == cls]
            distances = [cityblock(test_point, train_point) for train_point in class_points]
            distances.sort()
            kth_distance = distances[k-1] if k <= len(distances) else np.inf
            fom_per_class.append(kth_distance)

        min_fom = min(fom_per_class)
        detected_classes = [i for i, fom in enumerate(fom_per_class) if fom == min_fom]
        detected_class = min(detected_classes)
        predictions.append(detected_class)

    return np.array(predictions)

# Test vectors
X_test = np.array([
    [2.0, 0.8],  # Setosa
    [4.0, 0.8],  # Versicolor
    [6.5, 2.5],  # Virginica
    [4.5, 1.7],  # Virginica
    [4.8, 1.8],  # Virginica
    [5.0, 1.8],  # Versicolor
    [5.0, 1.5]   # Virginica
])

# Rounding features to integer values
X_test = np.round(X_test * 10).astype(int)
X_train = np.round(X_train * 10).astype(int)

# Test the classifier for k=1 and k=2
predictions_k1 = kthperclass_classifier(X_train[:, 2:], y_train, X_test, 1)
predictions_k2 = kthperclass_classifier(X_train[:, 2:], y_train, X_test, 2)
# Print the classifier output
predictions_k1, predictions_k2

from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

# Redefining true classes for the test vectors
true_classes = ["setosa", "versicolor", "virginica", "virginica", "virginica", "versicolor", "virginica"]
# Redefining the class mapping dictionary
class_mapping = {"setosa": 0, "versicolor": 1, "virginica": 2}
# Redefine the true classes in integer format
true_classes_int = [class_mapping[cls] for cls in true_classes]

# Compute confusion matrices for k=1 and k=2 with integer labels
confusion_matrix_k1 = confusion_matrix(true_classes_int, predictions_k1)
confusion_matrix_k2 = confusion_matrix(true_classes_int, predictions_k2)

# Function to calculate classification error probabilities
def calculate_error_probabilities(conf_matrix):
    total_samples = conf_matrix.sum()
    overall_error = (total_samples - np.trace(conf_matrix)) / total_samples
    conditional_errors = (conf_matrix.sum(axis=1) - np.diag(conf_matrix)) / conf_matrix.sum(axis=1)
    return overall_error, conditional_errors

# Error probabilities for k=1 and k=2
overall_error_k1, conditional_errors_k1 = calculate_error_probabilities(confusion_matrix_k1)
overall_error_k2, conditional_errors_k2 = calculate_error_probabilities(confusion_matrix_k2)

def display_confusion_matrix(conf_matrix, title):
  disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels =['setosa', 'versicolor','virginica'])
  disp.plot()
  plt.show()

# Displaying confusion matrices using sklearn's ConfusionMatrixDisplay
display_confusion_matrix(confusion_matrix_k1, "kthperclass Confusion Matrix (k=1)")
display_confusion_matrix(confusion_matrix_k2, "kthperclass Confusion Matrix (k=2)")
# Displaying the overall and conditional errors for k=1 and k=2
overall_error_k1, conditional_errors_k1, overall_error_k2, conditional_errors_k2

def split_data(X, y, Nt):
    # Function to split the dataset into training and testing sets, ensuring each class is equally represented.
    unique_classes = np.unique(y)
    X_train, X_test, y_train, y_test = [], [], [], []

    for cls in unique_classes:
        # Filter the data for the current class
        X_cls = X[y == cls]
        y_cls = y[y == cls]

        # Split the data for the current class
        X_train_cls, X_test_cls = X_cls[:Nt], X_cls[Nt:]
        y_train_cls, y_test_cls = y_cls[:Nt], y_cls[Nt:]

        # Append the split data to the overall training and testing sets
        X_train.append(X_train_cls)
        X_test.append(X_test_cls)
        y_train.append(y_train_cls)
        y_test.append(y_test_cls)

    # Concatenate the data from each class to form the final training and testing sets
    X_train = np.concatenate(X_train)
    X_test = np.concatenate(X_test)
    y_train = np.concatenate(y_train)
    y_test = np.concatenate(y_test)

    return X_train, X_test, y_train, y_test

# Using the split_data function to split the Iris dataset with Nt=30
Nt = 30  # Number of training vectors per class
X_train, X_test, y_train, y_test = split_data(X, y, Nt)

# Test split
X_train.shape, X_test.shape, y_train.shape, y_test.shape

def custom_knn_classifier(X_train, y_train, X_test, k):
    predictions = []

    for test_point in X_test:
        # Calculate Manhattan distances
        distances = [cityblock(test_point, train_point) for train_point in X_train]
        # Combine distances with labels and sort
        labeled_distances = sorted(zip(distances, y_train))
        # Get the k closest labels
        k_closest_labels = [label for _, label in labeled_distances[:k]]
        # Use a Counter to find the most common class, breaking ties by class number
        label_counter = Counter(k_closest_labels)
        most_common = label_counter.most_common()
        # Tie-breaking rule: choose the class with the smallest number in case of a tie
        if len(most_common) > 1 and most_common[0][1] == most_common[1][1]:
            prediction = min(most_common, key=lambda x: x[0])[0]
        else:
            prediction = most_common[0][0]
        predictions.append(prediction)
    return np.array(predictions)

# Function to evaluate and compare the classifiers
def evaluate_classifiers(X_train, y_train, X_test, y_test, k_range):
    kthperclass_results = {}
    knn_results = {}

    for k in k_range:
        # Test kthperclass classifier
        predictions_kthperclass = kthperclass_classifier(X_train, y_train, X_test, k)
        conf_matrix_kthperclass = confusion_matrix(y_test, predictions_kthperclass)
        overall_error_kthperclass, _ = calculate_error_probabilities(conf_matrix_kthperclass)
        kthperclass_results[k] = overall_error_kthperclass

        # Test kNN classifier
        predictions_knn = custom_knn_classifier(X_train, y_train, X_test, k)
        conf_matrix_knn = confusion_matrix(y_test, predictions_knn)
        overall_error_knn, _ = calculate_error_probabilities(conf_matrix_knn)
        knn_results[k] = overall_error_knn

    return kthperclass_results, knn_results

# Evaluate classifiers for k=1 through 17
kthperclass_errors, knn_errors = evaluate_classifiers(X_train, y_train, X_test, y_test, range(1, 18))

# Plot the graph for classification error probability vs. k value for both classifiers
plt.figure(figsize=(12, 7))
plt.plot(range(1, 18), list(kthperclass_errors.values()), 'o-', label='kthperclass')
plt.plot(range(1, 18), list(knn_errors.values()), 'x-', label='kNN')
plt.title('Figure 3. Pe vs. k for the kNN and kthperclass classifiers using the iris dataset')
plt.xlabel('k value')
plt.ylabel('Probability of classification error')
plt.xticks(range(1, 18))
plt.legend()
plt.show()

"""Software Requirements -\
Python version: 3.10.12\
NumPy version: 1.23.5\
scikit-learn version: 1.2.2\
Matplotlib version: 3.7.1\
Environment/IDE: Google Colab
"""