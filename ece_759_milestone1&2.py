# -*- coding: utf-8 -*-
"""ECE_759_Milestone1&2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-1_QxbKXPjBwCHRL-zVDRuoGuha7xSjV
"""

import matplotlib.pyplot as plt
from sklearn import datasets
import numpy as np

# Load the Iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target
feature_names = iris.feature_names
target_names = iris.target_names

# Define the plotting ranges for each feature based on Table A
feature_ranges = [(4, 8), (2, 5), (1, 7), (0, 3)]

# Define markers for each class
markers = ['o', 's', '^']

# Generate individual scatter plots for the Iris dataset
def plot_scatter(X, y, feature_names, target_names, feature_ranges, i, j, ax):

    for class_index in np.unique(y):
        ix = np.where(y == class_index)
        ax.scatter(X[ix, i], X[ix, j], label=target_names[class_index], marker=markers[class_index])
    ax.set_xlim(feature_ranges[i])
    ax.set_ylim(feature_ranges[j])
    ax.set_xlabel(feature_names[i])
    ax.set_ylabel(feature_names[j])
    ax.legend()
    ax.set_title(f'Iris Dataset: {feature_names[j]} vs {feature_names[i]}')

# Create a list to collect the figure objects
figures = []

for i in range(4):
    for j in range(i, 4):
        # Create a new figure for each subplot
        fig, ax = plt.subplots(figsize=(8, 6))
        plot_scatter(X, y, feature_names, target_names, feature_ranges, i, j, ax)
        figures.append(fig)  # Append the figure to the list

# Display all the figures
for fig in figures:
    plt.figure(fig.number)
    plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Test cases (Petal length, Petal width)
test_vectors = np.array([
    [2.0, 0.8],
    [4.0, 0.8],
    [6.5, 2.5],
    [4.5, 1.7],
    [4.8, 1.8],
    [5.0, 1.8],
    [5.0, 1.5]
])

# True classes for the test vectors
true_classes = ["Setosa", "Versicolor", "Virginica", "Virginica", "Virginica", "Versicolor", "Virginica"]

# Mapping of classes to integers for calculation purposes
class_mapping = {"Setosa": 0, "Versicolor": 1, "Virginica": 2}
true_classes_int = [class_mapping[cls] for cls in true_classes]

# Training data (only petal length and petal width are used)
X_2 = iris.data[:, 2:4]  # Only petal length and petal width

# Function to evaluate the classifier
def evaluate_knn(k):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_2, y)
    pred_classes = knn.predict(test_vectors)
    conf_matrix = confusion_matrix(true_classes_int, pred_classes, labels=[0, 1, 2])
    return pred_classes, conf_matrix

# Evaluate for k=1 and k=3
pred_classes_k1, conf_matrix_k1 = evaluate_knn(1)
pred_classes_k3, conf_matrix_k3 = evaluate_knn(3)

# Mapping back to class names for readability
pred_classes_k1_names = [iris.target_names[i] for i in pred_classes_k1]
pred_classes_k3_names = [iris.target_names[i] for i in pred_classes_k3]

# Display Confusion Matrices
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_k1, display_labels =['setosa', 'versicolor','virginica'])
disp.plot()
plt.show()

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_k3, display_labels =['setosa', 'versicolor','virginica'])
disp.plot()
plt.show()

pred_classes_k1_names

pred_classes_k3_names

conf_matrix_k1

conf_matrix_k3